sqoop list-databases \
  --connect "jdbc:mysql://ms.itversity.com:3306" \
  --username retail_user \
  --password itversity
  
  sqoop list-tables \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username retail_user \
  --password itversity
  
  sqoop eval \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username retail_user \
  --password itversity \
  --query "select count(1) from order_items"

sqoop import-all-tables \
  -m 12 \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --as-avrodatafile \
  --warehouse-dir=/user/hive/warehouse/sumit_retail_stage.db
  
  sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --as-textfile \
  --target-dir=/user/sumitpraggya/departments
  
   sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --as-sequencefile \
  --target-dir=/user/sumitpraggya/departments_seq
  
  sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --as-avrodatafile \
  --target-dir=/user/sumitpraggya/departments_avro
  
  sqoop import-all-tables \
  --num-mappers 1 \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --hive-import \
  --hive-overwrite \
  --create-hive-table \
  --compress \
  --compression-codec org.apache.hadoop.io.compress.SnappyCodec \
  --outdir java_files
  
  -- Basic import
  sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/sumitpraggya/departments 

-- Boundary Query and columns
sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/sumitpraggya/departments \
  -m 2 \
  --boundary-query "select 2, 8 from departments limit 1" \
  --columns department_id,department_name
  
  -- query and split-by
sqoop import \
 --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --query="select * from orders join order_items on orders.order_id = order_items.order_item_order_id where \$CONDITIONS" \
  --target-dir /user/sumitpraggya/order_join \
  --split-by order_id \
  --num-mappers 4
  
  -- Copying into existing table or directory (append)
-- Customizing number of threads (num-mappers)
-- Changing delimiter
sqoop import \
   --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/hive/warehouse/retail_ods.db/departments \
  --append \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --num-mappers 1 \
  --outdir java_files
  
  -- Importing table with out primary key using multiple threads (split-by)
-- When using split-by, using indexed column is highly desired
-- If the column is not indexed then performance will be bad 
-- because of full table scan by each of the thread
sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/hive/warehouse/retail_ods.db/departments \
  --append \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --split-by department_id \
  --outdir java_files
  
  -- Getting delta (--where)
sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/hive/warehouse/retail_ods.db/departments \
  --append \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --split-by department_id \
  --where "department_id > 7" \
  --outdir java_files
  
  -- Incremental load
sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/hive/warehouse/retail_ods.db/departments \
  --append \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --check-column "department_id" \
  --incremental append \
  --last-value 7 
  
  sqoop job --create sqoop_job \
  -- import \
 --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --target-dir /user/hive/warehouse/retail_ods.db/departments \
  --append \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --check-column "department_id" \
  --incremental append \
  --last-value 7 

sqoop job --list

sqoop job --show sqoop_job

sqoop job --exec sqoop_job

-- Hive related
-- Overwrite existing data associated with hive table (hive-overwrite)
sqoop import \
   --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --hive-home /user/hive/warehouse/retail_ods.db/sumit \
  --hive-import \
  --hive-overwrite \
  --hive-table departments 
  
  --Create hive table example
sqoop import \
  --connect "jdbc:mysql://ms.itversity.com:3306/retail_db" \
  --username=retail_user \
  --password=itversity \
  --table departments \
  --fields-terminated-by '|' \
  --lines-terminated-by '\n' \
  --hive-home /user/hive/warehouse \
  --hive-import \
  --hive-table departments_test \
  --create-hive-table 
  
